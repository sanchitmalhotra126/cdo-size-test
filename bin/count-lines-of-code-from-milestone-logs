#!/usr/bin/env ruby
require_relative '../deployment'
require 'cdo/aws/s3'

def count_lines_of_code(i)
  filename = File.basename(i.key)
  extname = File.extname(filename)
  path = pegasus_dir 'cache', filename
  IO.write path, i.value
  
  count_command = "cut -f10 | awk '{s+=$1} END {print s}'"
  
  case extname
  when '.gz'
    count = `gunzip -c #{path} | #{count_command}`.to_i
  when '.log'
    count = `cat #{path} | #{count_command}`.to_i
  else
    raise ArgumentError, "Don't know how to process #{extname} files."
  end
  
  FileUtils.rm path
  
  count
end

def main
  cache_file = pegasus_dir('cache','milestone-cache.json')
  cache = JSON.parse(IO.read(cache_file)) if File.file?(cache_file)
  cache ||= {}

  AWS::S3::connect!
  
  marker = nil
  total = 0

  while true
    objects = AWS::S3::Bucket.objects('cdo-logs', marker:marker)
    break if objects.size == 0

    objects.each do |i|
      match = i.key.match /^hosts\/(?<host>[^\/]+)\/dashboard\/milestone.log/
      next unless match
      
      host = match[:host]
      next if ['console', 'daemon', 'staging', 'test'].include? host
      
      cache[i.key] = count_lines_of_code(i) unless cache.has_key?(i.key) && File.extname(i.key) == '.gz'

      IO.write pegasus_dir('cache','milestone-cache.json'), JSON.pretty_generate(cache)

      total += cache[i.key]
      #puts "[#{total}] #{cache[i.key]} in #{i.key}"
    end
    marker = objects.last.key
  end

  puts total
end

main

