#!/usr/bin/env ruby
require_relative '../../lib/cdo/only_one'
exit unless only_one_running?(__FILE__)

require_relative '../../dashboard/config/environment'
exit unless rack_env?(:production) && CDO.dashboard_hostname == 'studio.code.org'

require 'cdo/aws/dms'
require 'cdo/aws/rds'
require 'cdo/chat_client'
require 'cdo/redshift_import'

# Delay between each check on task status.
TASK_STATUS_DELAY = 10.minutes
# TODO: (suresh) Can this dynamically reference the endpoint defined the in the production data stack?
CLONE_CLUSTER_ID = 'production-clone-for-redshift-export-cluster'.freeze
CLONE_DB_INSTANCE_ID = 'db.r4.4xlarge'.freeze

def main
  ChatClient.message 'data', 'Beginning daily export from Aurora MySQL database to Redshift.'
  # Delete clone of production cluster if it was incorrectly left behind by a previous execution of the import process.
  Cdo::RDS.delete_cluster(CLONE_CLUSTER_ID)
  Cdo::RDS.clone_cluster(
    source_cluster_id: CDO.db_cluster_id,
    clone_cluster_id: CLONE_CLUSTER_ID,
    instance_type: CLONE_DB_INSTANCE_ID
  )

  # Ensure that if any threads that are starting/monitoring DMS Tasks Raise an error, that the main thread here raises.
  Thread.abort_on_exception = true

  # Get list of tasks that should be executed daily.
  daily_tasks = Cdo::DMS::ReplicationTask.tasks_by_frequency('daily')
  # Spawn one thread for each replication task, so we can start and monitor them independently.
  daily_threads = []
  daily_tasks.each do |task|
    daily_threads << Thread.new {task.start(16.hours.div(TASK_STATUS_DELAY), TASK_STATUS_DELAY)}
  end
  daily_threads.each(&:join)

  # The DMS tasks exported to staging (_import_) tables to avoid disrupting queries on the production Redshift tables
  # during the lengthy table import process.  Rename the staging tables to the production table names to complete
  # the import process.
  RedshiftImport.complete_table_import(Cdo::DMS.redshift_schemas_imported_from_database)

  ChatClient.message 'data', "Completed daily export from Aurora MySQL database to Redshift."

  # Use the daily execution of this process on Friday nights Pacific Time (Saturday UTC) to kick off execution of tasks
  # that can only be run once a week, such as the export of the level_sources table which takes > 1 day.
  # Execution of this task will cause the Saturday PT (Sunday AM UTC) execution of this job to no-op due to
  # the only_one_running? restriction.
  if Date.today.saturday?
    ChatClient.message 'data', "Beginning weekly export from Aurora MySQL database to Redshift."
    weekly_tasks = Cdo::DMS::ReplicationTask.tasks_by_frequency('weekly')
    weekly_threads = []
    weekly_tasks.each do |task|
      weekly_threads << Thread.new {task.start(40.hours.div(TASK_STATUS_DELAY), TASK_STATUS_DELAY)}
    end
    weekly_threads.each(&:join)
    # Currently, the only weekly task (level_sources) is exported without using a staging table, so this won't find
    # any temp tables to rename.
    RedshiftImport.complete_table_import(Cdo::DMS.redshift_schemas_imported_from_database)
    ChatClient.message 'data', "Completed weekly export from Aurora MySQL database to Redshift."
  end
rescue StandardError => error
  ChatClient.message 'data', "Error during export from Aurora MySQL database to Redshift #{error.message}", color: 'red'
  raise error
ensure
  Cdo::RDS.delete_cluster(CLONE_CLUSTER_ID)
end

main
