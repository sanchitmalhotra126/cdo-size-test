#!/usr/bin/env ruby
require_relative '../deployment'
require_relative '../lib/cdo/aws/s3'
require_relative '../shared/middleware/helpers/storage_id'

MAX_THREADS = 200
MAX_KEYS = 1000

regex = ARGV[0].to_s.strip
raise "usage: #{$0} regex > output.tsv" unless !regex.empty?

# Searches all applab source code for the specified regex and prints results to a tsv file.
# This is useful for seeing if we will break anyone's program if we change how a block works.
#
# The 'match' field is either the first '()' grouping in the regex if one is specified, or
# the entire matched string otherwise.
#
# With 200 threads this script takes approximately 1 hour to process 800,000 source files
# on production-console.

# print tsv headers
puts %w{owner_storage_id match project_url}.join("\t")

s3 = Aws::S3::Client.new
marker = nil
bucket = CDO.sources_s3_bucket
base_dir = CDO.sources_s3_directory
count = 0

loop do
  contents = s3.list_objects(bucket: bucket, prefix: base_dir, :max_keys=>MAX_KEYS, :marker=>marker).contents
  break if contents.empty?
  marker = contents.last.key

  contents.each_slice(MAX_THREADS) do |chunk|
    threads = []
    chunk.each do |fileinfo|
      threads << Thread.new do
        _, owner_storage_id, channel_id, filename = %r{#{base_dir}/([^/]+)/([^/]+)/([^/]+)$}.match(fileinfo.key).to_a
        if filename == 'main.json'
          body = s3.get_object(bucket: bucket, key: fileinfo.key)[:body].read
          source = JSON.parse(body)['source']
          match = source.match(regex)
          if match
            channel = storage_encrypt_channel_id(owner_storage_id, channel_id)
            project_url = "https://#{CDO.dashboard_hostname}/projects/applab/#{channel}/view"
            puts "#{owner_storage_id}\t#{match[1] || match[0]}\t#{project_url}"
          end
        end
      end
    end
    threads.each &:join
  end
  count += contents.length
  $stderr.puts "#{count} files scanned..."
end
$stderr.puts "#{count} files scanned total"
